# Testing Azure ML Pipeline - After Adding Secrets

## âœ… Prerequisites Check

Before testing, confirm you have:
- [x] Added `AZURE_CREDENTIALS` secret to GitHub
- [x] Added `AZURE_SUBSCRIPTION_ID` secret to GitHub
- [x] Both secrets visible at: https://github.com/jmcginnity2025/mlops-cw2-fresh/settings/secrets/actions

---

## ðŸ§ª Test Method 1: Automatic Trigger (Recommended)

This tests the full automated workflow.

### Step 1: Make a Small Change

```bash
cd "C:\AI Masters\AI Masters\Infrastucture Module - Azure\CW2\mlops-cw2-fresh"

# Add a test comment to trigger pipeline
echo "# Test Azure ML pipeline - $(date)" >> README.md

# Commit and push
git add README.md
git commit -m "Test Azure ML automated pipeline"
git push
```

### Step 2: Watch Both Pipelines

Go to: **https://github.com/jmcginnity2025/mlops-cw2-fresh/actions**

You should see **TWO pipelines** running simultaneously:

1. **ML CI/CD Pipeline** (Local training - already working âœ…)
   - Job 1: Data Preprocessing
   - Job 2: Train Models
   - Job 3: Evaluate & Regression Test
   - Job 4: Version & Tag Models
   - **Duration**: ~3-5 minutes

2. **Azure ML Pipeline** (Cloud training - NEW! ðŸ†•)
   - Job 1: Submit Training to Azure ML
   - Job 2: Compare Models
   - Job 3: Pipeline Success
   - **Duration**: ~15-20 minutes (includes environment build)

---

## ðŸ§ª Test Method 2: Manual Trigger

If you prefer not to commit, trigger manually:

### Step 1: Open Workflow Page

Go to: **https://github.com/jmcginnity2025/mlops-cw2-fresh/actions**

### Step 2: Select Azure ML Pipeline

Click on **"Azure ML Pipeline"** in the left sidebar

### Step 3: Run Workflow

1. Click **"Run workflow"** button (top right)
2. Select branch: **main**
3. Click green **"Run workflow"** button

### Step 4: Monitor Execution

Click on the running workflow to see live logs

---

## ðŸ“Š What to Expect

### GitHub Actions Side:

**Job 1: Submit Training to Azure ML**
```
âœ… Connected to: cw2-mlops-workspace
âœ… Dataset: support-tickets-dataset
âœ… Job submitted: [job-name]
Status: Running
â³ Waiting for job to complete...
[Live streaming logs from Azure...]
ðŸ“Š Final status: Completed
âœ… Training completed successfully!
```

**Job 2: Compare Models**
```
Latest run: [job-name]
Status: Completed
âœ… Models trained successfully!
âœ… Both iterations completed
```

**Job 3: Pipeline Success**
```
================================================
ðŸŽ‰ AZURE ML PIPELINE SUCCESSFUL!
================================================
Training completed in Azure ML
Models logged with MLflow
Ready for deployment
================================================
```

### Azure ML Studio Side:

**1. Jobs Page**
- Go to: https://ml.azure.com â†’ Jobs
- You'll see: `github-run-[number]`
- Status: Running â†’ Completed

**2. Compute Page**
- Go to: https://ml.azure.com â†’ Compute
- `cpu-cluster` will show:
  - Status: Busy (during training)
  - Status: Idle (after completion)
  - Then scales to 0 nodes (cost saving!)

**3. MLflow Tracking**
- Go to: https://ml.azure.com â†’ Jobs â†’ [your job]
- Click on **"Metrics"** tab
- You'll see:
  - `iteration_1_train_accuracy`
  - `iteration_1_test_accuracy`
  - `iteration_1_test_f1`
  - `iteration_2_train_accuracy`
  - `iteration_2_test_accuracy`
  - `iteration_2_test_f1`
  - All logged and tracked!

**4. Models Page**
- Go to: https://ml.azure.com â†’ Models
- Both model files saved:
  - `iteration_1_model.pkl`
  - `iteration_2_model.pkl`

---

## ðŸ” Monitoring Tips

### Watch GitHub Actions Live:

1. Go to Actions tab
2. Click on running workflow
3. Click on job (e.g., "Submit Training to Azure ML")
4. You'll see live logs streaming from Azure!

### Watch Azure ML Studio:

1. Open: https://ml.azure.com
2. Navigate to: Jobs â†’ All jobs
3. Find: `github-run-[number]`
4. Click to see:
   - Live logs
   - Metrics being logged
   - Resource utilization
   - Cost tracking

### Best Practice:

**Open both side-by-side:**
- Left monitor: GitHub Actions (shows submission and orchestration)
- Right monitor: Azure ML Studio (shows actual training progress)

---

## â±ï¸ Timeline Expectations

### First Run (Cold Start):
```
0:00 - GitHub Actions starts
0:30 - Azure ML receives job
1:00 - Environment build starts (Docker image)
8:00 - Environment build completes
9:00 - Compute scales up (0â†’1 nodes)
10:00 - Training starts
11:00 - Iteration 1 completes
12:00 - Iteration 2 completes
13:00 - Metrics logged to MLflow
14:00 - Models saved
15:00 - Job completes
15:30 - Compute scales down (1â†’0 nodes)
```

### Subsequent Runs (Warm Start):
```
0:00 - GitHub Actions starts
0:30 - Azure ML receives job
1:00 - Uses cached environment (faster!)
2:00 - Compute scales up
3:00 - Training starts
4:00 - Iteration 1 completes
5:00 - Iteration 2 completes
6:00 - Job completes
7:00 - Compute scales down
```

**Note**: First run takes longer due to Docker image build!

---

## ðŸŽ¯ Success Indicators

### In GitHub Actions:

âœ… All jobs show green checkmarks
âœ… "Submit Training to Azure ML" completed
âœ… "Compare Models" passed
âœ… Summary shows both iterations trained

### In Azure ML Studio:

âœ… Job status: Completed
âœ… All metrics logged to MLflow
âœ… Both model files saved
âœ… Compute scaled back to zero
âœ… No errors in logs

---

## ðŸš¨ Troubleshooting

### "Error: AZURE_CREDENTIALS not found"

**Cause**: Secret not added or wrong name

**Fix**:
1. Go to: https://github.com/jmcginnity2025/mlops-cw2-fresh/settings/secrets/actions
2. Verify `AZURE_CREDENTIALS` exists (shows *****)
3. Name must be EXACTLY: `AZURE_CREDENTIALS` (all caps, no spaces)

### "Authentication failed"

**Cause**: JSON credentials malformed

**Fix**:
1. Check ADD_GITHUB_SECRETS.md for correct JSON format
2. Ensure you copied entire JSON (all 10 lines)
3. No extra spaces or line breaks
4. Starts with `{` and ends with `}`

### "Workspace not found"

**Cause**: Wrong subscription ID or workspace deleted

**Fix**:
```bash
# Verify workspace exists
az ml workspace show \
  --name cw2-mlops-workspace \
  --resource-group cw2-mlops-rg
```

### "Dataset not found"

**Cause**: Dataset not uploaded to Azure ML

**Fix**:
```bash
cd "C:\AI Masters\AI Masters\Infrastucture Module - Azure\CW2\mlops-cw2-fresh"
python submit_training_job.py
```

This will re-upload the dataset if missing.

### "Environment build failed"

**Cause**: Missing dependencies in environment.yml

**Check**: Job logs in Azure ML Studio â†’ Errors tab

### Job stuck "Running" for > 30 minutes

**Possible causes**:
- Compute quota exceeded
- Region capacity issues
- Cost limit reached

**Fix**:
```bash
# Check compute status
az ml compute show \
  --name cpu-cluster \
  --workspace-name cw2-mlops-workspace \
  --resource-group cw2-mlops-rg
```

---

## ðŸ“¸ Screenshots for Coursework

After successful run, capture:

### GitHub Actions:
1. **Actions overview** - Both pipelines listed
2. **Azure ML Pipeline** - All 3 jobs green
3. **Job logs** - "Submit Training to Azure ML" logs
4. **Summary page** - Pipeline success message

### Azure ML Studio:
5. **Jobs page** - Your completed job
6. **Job details** - Status, duration, compute used
7. **Metrics tab** - MLflow metrics for both iterations
8. **Logs tab** - Training output
9. **Models** - Both iteration models saved
10. **Compute** - Showing auto-scale to zero

### Comparison View:
11. **Side-by-side** - GitHub Actions + Azure ML Studio
12. **MLflow dashboard** - Metrics comparison

---

## ðŸŽ“ What This Demonstrates for Coursework

### Model Development:
âœ… Two iterations trained (Random Forest + XGBoost)
âœ… Hyperparameter differences documented
âœ… Performance comparison automated

### CI/CD Pipeline:
âœ… Automated trigger on git push
âœ… GitHub Actions orchestration
âœ… Azure ML integration
âœ… Sequential job dependencies

### Deployment:
âœ… Cloud-based training
âœ… Scalable compute (auto-scale)
âœ… Environment management (Docker)
âœ… Model versioning

### Monitoring:
âœ… MLflow metric tracking
âœ… Live log streaming
âœ… Performance comparison
âœ… Resource utilization tracking

### Retraining:
âœ… Automatic on new commits
âœ… Reproducible training
âœ… Version-controlled code
âœ… Compute auto-scaling

### Governance:
âœ… Git version control
âœ… Audit trail (GitHub Actions logs)
âœ… Access control (secrets management)
âœ… Cost tracking (Azure ML compute)

**All CW2 requirements met!** ðŸŽ‰

---

## ðŸ”„ After Testing

### If Successful:

1. **Take screenshots** (see list above)
2. **Document results** in coursework report
3. **Keep running** for future commits (fully automated!)
4. **Cost monitoring**: Compute scales to zero = minimal cost

### Cost Optimization:

The pipeline is already optimized:
- Compute scales to 0 when idle
- Only runs when you commit
- Uses smallest viable VM (STANDARD_DS3_v2)
- Efficient environment caching

**Expected cost per run**: ~Â£0.50-Â£1.00 (15-20 min training)

### Next Commits:

Every future commit to main will:
1. Trigger local pipeline (GitHub Actions VM - free)
2. Trigger Azure ML pipeline (cloud compute - paid)

If you want to **disable Azure ML pipeline temporarily**:
- Don't commit to main (use feature branches)
- Or comment out the workflow file
- Local pipeline will still run!

---

## âœ… Success Checklist

Before marking complete, verify:

- [ ] GitHub secrets added (2 secrets visible)
- [ ] Pipeline triggered (manually or via commit)
- [ ] GitHub Actions shows both pipelines running
- [ ] Azure ML job appears in studio
- [ ] Training completes successfully
- [ ] MLflow metrics logged
- [ ] Both models saved
- [ ] Compute scales back to zero
- [ ] All jobs green in GitHub Actions
- [ ] Screenshots taken for coursework

---

## ðŸŽ‰ Next Steps After Success

1. **Document your setup** - Write up the implementation
2. **Analyze metrics** - Compare model performance
3. **Coursework submission** - Include screenshots and analysis
4. **Optional improvements**:
   - Add model deployment step
   - Implement A/B testing
   - Add monitoring dashboards
   - Set up alerts

---

## ðŸ’¡ Pro Tips

### Faster Testing:

If you want to test multiple times quickly:
```bash
# Quick commit script
echo "test" >> test.txt
git add test.txt
git commit -m "Test run"
git push
```

### Cost Control:

Monitor costs at:
- https://portal.azure.com â†’ Cost Management
- Set budget alerts
- Review compute usage

### Debugging:

If something fails:
1. Check GitHub Actions logs first
2. Then check Azure ML Studio logs
3. Look for specific error messages
4. Check this troubleshooting section

---

## ðŸ“ž Need Help?

If you encounter issues:

1. **Check logs** - GitHub Actions and Azure ML Studio
2. **Verify secrets** - Correct format and values
3. **Test connectivity** - Can you access Azure ML manually?
4. **Review setup** - Follow ADD_GITHUB_SECRETS.md step-by-step

---

**Good luck with testing!** ðŸš€

Once the pipeline runs successfully, you'll have a complete, production-grade MLOps system ready for your coursework submission!
